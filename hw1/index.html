<html>
  <head>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default"></script>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap"
      rel="stylesheet"
    />
    <style>
      h1 {
        text-align: center;
      }

      .container {
        margin: 0 auto;
        padding: 60px 20%;
      }

      figure {
        text-align: center;
      }

      img {
        display: inline-block;
      }

      body {
        font-family: "Inter", sans-serif;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
      <div style="text-align: center">Names:</div>

      <br />

      Link to webpage: (TODO)
      <a
        href="https://cal-cs184-student.github.io/hw-webpages-Hoponga/hw1/index.html"
        >https://cal-cs184-student.github.io/hw-webpages-Hoponga/hw1/index.html</a
      >

      <br />

      Link to GitHub repository: (TODO)
      <a href="https://github.com/cal-cs184-student/hw1-rasterizer-pgang"
        >https://github.com/cal-cs184-student/hw1-rasterizer-pgang</a
      >

      <figure>
        <img src="lion.jpg" alt="Lion" style="width: 50%" />
        <figcaption>You can add images with captions!</figcaption>
      </figure>

      <!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

      <h2>Overview</h2>
      Give a high-level overview of what you implemented in this homework. Think
      about what you've built as a whole. Share your thoughts on what
      interesting things you've learned from completing the homework.

      <h2>Task 1: Drawing Single-Color Triangles</h2>

      We rasterize triangles by first drawing a bounding box around the triangle
      (by taking the min x and max x of the triangle points and correspondingly
      for y), so our algorithm performs no worse than one that checks the
      bounding box as it does just check the bounding box. Then, for each pixel
      in the bounding box, we check if the pixel is inside the triangle by using
      barycentric coordinates, specifically using the ratio of area formula for
      barycentric coordinates and ensuring that they sum to one.

      <figure>
        <img src="task1/triangles.png" alt="Triangles" style="width: 50%" />
        <figcaption>Example image for Task 1.</figcaption>
      </figure>

      <h2>Task 2: Antialiasing by Supersampling</h2>

      Our supersampling algorithm "splits" every pixel into a grid of subpixels
      and then checks if each subpixel is inside a particular triangle. Each of
      these subpixel colors is stored in a sample buffer, and when the true
      frame buffer colors are required for rendering, we average out the colors
      of the subpixels in the sample buffer to get the true pixel color that is
      shown. Supersampling is useful because it allows us to get smoother edges
      on our triangles, as we can capture more detail about the triangle's shape
      by checking the subpixels. This is especially important for small
      triangles that may only cover a few pixels, as without supersampling they
      may appear jagged or aliased. We can notice the effects of supersampling
      in the image below by zooming in on the "jaggies" which with supersampling
      rate 16 are smoother. Without supersampling:
      <figure>
        <img
          src="task2/full_image_sample_rate_1.png"
          alt="Lion"
          style="width: 100%"
        />
        <figcaption>Sample Rate 1 (Full Image)</figcaption>
      </figure>

      <figure>
        <img
          src="task2/full_image_sample_rate_4.png"
          alt="Lion"
          style="width: 100%"
        />
        <figcaption>Sample Rate 4 (Full Image)</figcaption>
      </figure>

      <figure>
        <img
          src="task2/full_image_sample_rate_16.png"
          alt="Lion"
          style="width: 100%"
        />
        <figcaption>Sample Rate 16 (Full Image)</figcaption>
      </figure>

      <figure>
        <img src="task2/zoomed_sample_rate_1.png" style="width: 100%" />
        <figcaption>Sample Rate 1 (zoomed on red triangle)</figcaption>
      </figure>

      <figure>
        <img src="task2/zoomed_sample_rate_4.png" style="width: 100%" />
        <figcaption>Sample Rate 4 (zoomed on red triangle)</figcaption>
      </figure>

      <figure>
        <img src="task2/zoomed_sample_rate_16.png" style="width: 100%" />
        <figcaption>Sample Rate 16 (zoomed on red triangle)</figcaption>
      </figure>

      <h2>Task 3: Transforms</h2>

      We implement transformations (specifically, translation, rotation, and
      scaling) using homogeneous coordinates matrices. Consider the default
      robot position:

      <figure>
        <img src="default_robot.png" alt="Lion" style="width: 50%" />
        <figcaption>Default robot position.</figcaption>
      </figure>

      Anirudh and I are staunch yoga enthusiasts, so we decided to make our
      robot do the lotus pose (Padmasana). We apply a rotation to each leg of
      the robot to achieve this pose.
      <figure>
        <img src="buddhist_pose.png" alt="Lion" style="width: 50%" />
        <figcaption>Robot in lotus pose.</figcaption>
      </figure>

      <h2>Task 4: Barycentric coordinates</h2>
      Say you have some number of points (in our case 3 vertices A B C
      representing a triangle). Barycentric coordinates are a way to represent
      another point as a weighted sum of these points. For example, we can
      represent some point P = w1 * A + w2 * B + w3 * C where w1+w2+w3 must sum
      to 1. Barycentric coordinates are great for interpolating values (ex:
      colors) in between the vertices. For example, if our query point P is very
      close to an existing vertex, the corresponding weight for that vertex will
      be very high.

      <figure>
        <img
          src="task4/color_triangle.png"
          alt="Color Triangle"
          style="width: 50%"
        />
        <figcaption>
          This image shows barycentric coordinates used to interpolate colors
          for a color triangle. One vertex is red, one is green, and one is
          blue. The sample rate is 1.
        </figcaption>
      </figure>

      <figure>
        <img src="task4/color_wheel.png" alt="Color Wheel" style="width: 50%" />
        <figcaption>
          This image shows barycentric coordinates used to interpolate colors
          for a color wheel.
        </figcaption>
      </figure>

      <h2>Task 5: "Pixel sampling" for texture mapping</h2>

      The texture is stored as a mipmap, which has multiple resolutions of the
      texture. For this task, we use just the full resolution texture (level 0).
      We will refer to these texture grid elements as texels.

      <br />

      Our goal in this task is to do pixel sampling for texture mapping. This
      means that for each pixel in the triangle, we need to find the texel
      coordinates to sample from in the texture. Here's an algorithmic
      description that goes more into detail:
      <pre>
		<code>
			Take a triangle with vertices (x0, y0), (x1, y1), (x2, y2) whose
			corresponding texel coordinates are (u0, v0), (u1, v1), (u2, v2).
			

			Figure out which pixels are covered by the triangle. 

			for each covered_pixel:
				Convert from pixel coordinates to barycentric coordinates. 
				
				Using the barycentric coordinates, interpolate which u and v 
				to sample from in the texture.

				Sample the texture from the interpolated texel coordinates, 
				using either nearest neighbor or bilinear interpolation.
		</code>
		</pre>
      <br />
      Nearest neighbor sampling takes the query coordinate and rounds it to the
      nearest texel coordinate. Bilinear sampling takes the query coordinate and
      interpolates between the 4 nearest texel coordinates. Each texel
      coordinate's value is weighted by how close the query coordinate is to
      that texel coordinate.

      <br />

      The following images show a rasterized Earth map. In the top right is a
      zoomed in part of the image.

      <figure>
        <img src="task5/nn_sample_rate_1.png" style="width: 50%" />
        <figcaption>
          This image shows nearest neighbor sampling (sample rate 1).
        </figcaption>
      </figure>
      <figure>
        <img src="task5/bilinear_sample_rate_1.png" style="width: 50%" />
        <figcaption>
          This image shows bilinear sampling (sample rate 1).
        </figcaption>
      </figure>
      <figure>
        <img src="task5/nn_sample_rate_16.png" style="width: 50%" />
        <figcaption>
          This image shows nearest neighbor sampling (sample rate 16).
        </figcaption>
      </figure>
      <figure>
        <img src="task5/bilinear_sample_rate_16.png" style="width: 50%" />
        <figcaption>
          This image shows bilinear sampling (sample rate 16).
        </figcaption>
      </figure>

      The first image (nearest neighbor, sample_rate=1) has a lot of aliasing
      with many gaps between pixels corresponding to the same edge.
      <br />
      <br />
      The second image (bilinear, sample_rate=1) has similar incorrect gaps
      between parts of the same edge, but the pixel values are more smoothed.
      <br />
      <br />
      The third image (nearest neighbor, sample_rate=16) does not have gaps
      within the same edges, but the pixel values are more high frequency.
      <br />
      <br />
      The fourth image (bilinear, sample_rate=16) does not have gaps within the
      same edges, and the pixel values are more smoothed. These results are as
      expected.
      <br />
      <br />
      Generally, bilinear sampling produces more smooth pixel values than
      nearest neighbor sampling. Also, a higher sample rate generally produces
      more correct values (here with fewer gaps) as we are sampling more points
      to decide a single pixel's value.

      <h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>

      In the previous task, we only had one resolution of the texture. In a mip
      map, we have multiple resolutions of the texture (specifically,
      resolutions of powers of 2 factors smaller than the original texture). We
      want to sample resolutions depending on the Jacobian of each triangle
      which represents its depth distortion. Specifically, if we find that the
      triangle is very distorted, which we represent by the derivative of texel
      map coordinates with respect to screen coordinates, then a large area of
      texture maps to a small area of the screen and we can afford a lower
      resolution in this area. Whereas if we have a flatter triangle where this
      derivative is lesser, the map is more one to one and we require a higher
      resolution. This motivates the formulas for L and d in mipmap level
      sampling. We implement this procedure by approximating the du(dv)/dx(dy)
      derivatives using finite differences, and then use the maximum of these
      derivatives to determine the appropriate mipmap level. We could either
      sampling levels by always sampling the highest resolution (which is
      L_zero, memory efficient as we dont even need the mipmap), rounding the
      above-decribed level to the nearest mipmap level (L_nearest, which is less
      memory efficient as now it requires the mipmap and requires a bit more
      computation for those derivatives), or doing linear interpolation
      (L_LINEAR) which is similarly memory inefficient and also a bit more
      computationally expensive as we have to sample two texel maps and
      interpolate between them for one pixel. First we look at L_zero and
      P_nearest
      <figure>
        <img
          src="task6/levelzero_nearestpixel.png"
          alt="L_zero P_nearest"
          style="width: 50%"
        />
        <figcaption>
          This image shows the L_zero and P_nearest sampling method for texture
          mapping.
        </figcaption>
      </figure>

      Then we look at L_zero and P_bilinear
      <figure>
        <img
          src="task6/levelzero_bilinearpixel.png"
          alt="L_zero P_bilinear"
          style="width: 50%"
        />
        <figcaption>
          This image shows the L_zero and P_bilinear sampling method for texture
          mapping.
        </figcaption>
      </figure>

      Then we look at L_nearest and P_nearest
      <figure>
        <img
          src="task6/levelnearest_nearestpixel.png"
          alt="L_nearest P_nearest"
          style="width: 50%"
        />
        <figcaption>
          This image shows the L_nearest and P_nearest sampling method for
          texture mapping.
        </figcaption>
      </figure>

      ANd finally we look at L_nearest and P_bilinear
      <figure>
        <img
          src="task6/levelnearest_bilinearpixel.png"
          alt="L_nearest P_bilinear"
          style="width: 50%"
        />
        <figcaption>
          This image shows the L_nearest and P_bilinear sampling method for
          texture mapping.
        </figcaption>
      </figure>

      Some trends we see are that using L_zero over L_nearest gives sharper
      images but also more aliasing, and using P_bilinear over P_nearest gives
      smoother images but also more blurring. We focus in on a specific part of
      the globe texture that demonstrates these trends.

      <h2>(Optional) Task 7: Extra Credit - Draw Something Creative!</h2>
    </div>
  </body>
</html>
